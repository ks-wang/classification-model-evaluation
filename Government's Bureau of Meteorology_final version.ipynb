{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import the required libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Libraries required for this lab are listed below. The libraries pre-installed on Skills Network Labs are commented.\n",
    "# !mamba install -qy pandas==1.3.4 numpy==1.21.4 seaborn==0.9.0 matplotlib==3.5.0 scikit-learn==0.20.1\n",
    "# Note: If your environment doesn't support \"!mamba install\", use \"!pip install\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surpress warnings:\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you are running the lab in your  browser, so we will install the libraries using ``piplite``\n",
    "import piplite\n",
    "await piplite.install(['pandas'])\n",
    "await piplite.install(['numpy'])\n",
    "await piplite.install(['tabulate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyodide.http import pyfetch\n",
    "\n",
    "async def download(url, filename):\n",
    "    response = await pyfetch(url)\n",
    "    if response.status == 200:\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(await response.bytes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillUp/labs/ML-FinalAssignment/Weather_Data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "await download(path, \"Weather_Data.csv\")\n",
    "filename =\"Weather_Data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>WindDir3pm</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/1/2008</td>\n",
       "      <td>19.5</td>\n",
       "      <td>22.4</td>\n",
       "      <td>15.6</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>S</td>\n",
       "      <td>SSW</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1017.4</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>20.7</td>\n",
       "      <td>20.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/2/2008</td>\n",
       "      <td>19.5</td>\n",
       "      <td>25.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>W</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>73</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>1016.4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>22.4</td>\n",
       "      <td>24.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2/3/2008</td>\n",
       "      <td>21.6</td>\n",
       "      <td>24.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>ESE</td>\n",
       "      <td>ESE</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>86</td>\n",
       "      <td>1016.7</td>\n",
       "      <td>1015.6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2/4/2008</td>\n",
       "      <td>20.2</td>\n",
       "      <td>22.8</td>\n",
       "      <td>18.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>NNE</td>\n",
       "      <td>E</td>\n",
       "      <td>...</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "      <td>1014.2</td>\n",
       "      <td>1011.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>20.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2/5/2008</td>\n",
       "      <td>19.7</td>\n",
       "      <td>25.7</td>\n",
       "      <td>77.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>W</td>\n",
       "      <td>41</td>\n",
       "      <td>NNE</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>74</td>\n",
       "      <td>1008.3</td>\n",
       "      <td>1004.8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>22.5</td>\n",
       "      <td>25.5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date  MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine WindGustDir  \\\n",
       "0  2/1/2008     19.5     22.4      15.6          6.2       0.0           W   \n",
       "1  2/2/2008     19.5     25.6       6.0          3.4       2.7           W   \n",
       "2  2/3/2008     21.6     24.5       6.6          2.4       0.1           W   \n",
       "3  2/4/2008     20.2     22.8      18.8          2.2       0.0           W   \n",
       "4  2/5/2008     19.7     25.7      77.4          4.8       0.0           W   \n",
       "\n",
       "   WindGustSpeed WindDir9am WindDir3pm  ...  Humidity9am  Humidity3pm  \\\n",
       "0             41          S        SSW  ...           92           84   \n",
       "1             41          W          E  ...           83           73   \n",
       "2             41        ESE        ESE  ...           88           86   \n",
       "3             41        NNE          E  ...           83           90   \n",
       "4             41        NNE          W  ...           88           74   \n",
       "\n",
       "   Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  Temp3pm  RainToday  \\\n",
       "0       1017.6       1017.4         8         8     20.7     20.9        Yes   \n",
       "1       1017.9       1016.4         7         7     22.4     24.8        Yes   \n",
       "2       1016.7       1015.6         7         8     23.5     23.0        Yes   \n",
       "3       1014.2       1011.8         8         8     21.4     20.9        Yes   \n",
       "4       1008.3       1004.8         8         8     22.5     25.5        Yes   \n",
       "\n",
       "   RainTomorrow  \n",
       "0           Yes  \n",
       "1           Yes  \n",
       "2           Yes  \n",
       "3           Yes  \n",
       "4           Yes  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Weather_Data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney_processed = pd.get_dummies(data=df, columns=['RainToday', 'WindGustDir', 'WindDir9am', 'WindDir3pm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney_processed.replace(['No', 'Yes'], [0,1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data and Test Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney_processed.drop('Date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sydney_processed = df_sydney_processed.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_sydney_processed.drop(columns='RainTomorrow', axis=1)\n",
    "Y = df_sydney_processed['RainTomorrow']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `10`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (2616, 66) (2616,)\n",
      "Test set: (655, 66) (655,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, Y, test_size=.2, random_state=10)\n",
    "print ('Train set:', x_train.shape,  y_train.shape)\n",
    "print ('Test set:', x_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2) Create and train a Linear Regression model called LinearReg using the training data (`x_train`, `y_train`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:  [-2.36862502e-02  1.30060400e-02  7.29929096e-04  6.49363254e-03\n",
      " -3.51643494e-02  4.23733388e-03  1.82788340e-03  7.90075624e-04\n",
      "  9.56782146e-04  8.55986210e-03  7.69992241e-03 -9.24589847e-03\n",
      " -8.88017645e-03  1.00487910e-02  1.44675206e-02 -3.48703168e-03\n",
      "  8.47590247e+08  8.47590247e+08 -6.41324526e+09 -6.41324526e+09\n",
      " -6.41324526e+09 -6.41324526e+09 -6.41324526e+09 -6.41324526e+09\n",
      " -6.41324526e+09 -6.41324526e+09 -6.41324526e+09 -6.41324526e+09\n",
      " -6.41324526e+09 -6.41324526e+09 -6.41324526e+09 -6.41324526e+09\n",
      " -6.41324526e+09 -6.41324526e+09  1.43257002e+10  1.43257002e+10\n",
      "  1.43257002e+10  1.43257002e+10  1.43257002e+10  1.43257002e+10\n",
      "  1.43257002e+10  1.43257002e+10  1.43257002e+10  1.43257002e+10\n",
      "  1.43257002e+10  1.43257002e+10  1.43257002e+10  1.43257002e+10\n",
      "  1.43257002e+10  1.43257002e+10 -1.09414185e+10 -1.09414185e+10\n",
      " -1.09414185e+10 -1.09414185e+10 -1.09414185e+10 -1.09414185e+10\n",
      " -1.09414185e+10 -1.09414185e+10 -1.09414185e+10 -1.09414185e+10\n",
      " -1.09414185e+10 -1.09414185e+10 -1.09414185e+10 -1.09414185e+10\n",
      " -1.09414185e+10 -1.09414185e+10]\n"
     ]
    }
   ],
   "source": [
    "LinearReg = LinearRegression()\n",
    "x = np.asanyarray(x_train)\n",
    "y = np.asanyarray(y_train)\n",
    "LinearReg.fit(x_train, y_train)\n",
    "print ('Coefficients: ', LinearReg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 0.12\n",
      "Variance score: 0.43\n"
     ]
    }
   ],
   "source": [
    "predictions = LinearReg.predict(x_test)\n",
    "x = np.asanyarray(x_test)\n",
    "y = np.asanyarray(y_test)\n",
    "print(\"Residual sum of squares: %.2f\"\n",
    "      % np.mean((predictions - y) ** 2))\n",
    "print('Variance score: %.2f' % LinearReg.score(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q4) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 0.26\n",
      "Residual sum of squares (MSE): 0.12\n",
      "R2-score: -0.38\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "LinearRegression_MAE = metrics.mean_absolute_error(predictions, y_test)\n",
    "LinearRegression_MSE = metrics.mean_squared_error(predictions, y_test)\n",
    "LinearRegression_R2 = metrics.r2_score(predictions, y_test)\n",
    "print(\"Mean absolute error: %.2f\" % LinearRegression_MAE)\n",
    "print(\"Residual sum of squares (MSE): %.2f\" % LinearRegression_MSE)\n",
    "print(\"R2-score: %.2f\" % LinearRegression_R2 ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q5) Show the MAE, MSE, and R2 in a tabular format using data frame for the linear model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'error_type':['LinearRegression_MAE','LinearRegression_MSE','LinearRegression_R2'],\n",
    "        \n",
    "        'value':[LinearRegression_MAE,LinearRegression_MSE,LinearRegression_R2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+-----------+\n",
      "|    | error_type           |     value |\n",
      "|----+----------------------+-----------|\n",
      "|  0 | LinearRegression_MAE |  0.256319 |\n",
      "|  1 | LinearRegression_MSE |  0.11572  |\n",
      "|  2 | LinearRegression_R2  | -0.384754 |\n",
      "+----+----------------------+-----------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "Report =  pd.DataFrame(dict)\n",
    "print(tabulate(Report, headers = 'keys', tablefmt = 'psql'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q6) Create and train a KNN model called KNN using the training data (`x_train`, `y_train`) with the `n_neighbors` parameter set to `4`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors=4)\n",
    "KNN.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q7) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = KNN.predict(x_test)\n",
    "predictions[0:5] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q8) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score:  0.8183206106870229\n",
      "KNN_JaccardIndex:  0.4251207729468599\n",
      "KNN F1 score :  0.5966101694915255\n",
      "KNN Log Loss :  6.275011880511857\n"
     ]
    }
   ],
   "source": [
    "KNN_Accuracy_Score =  metrics.accuracy_score(y_test, predictions)\n",
    "KNN_JaccardIndex = metrics.jaccard_score(y_test, predictions)\n",
    "KNN_F1_Score = metrics.f1_score(y_test, predictions)\n",
    "KNN_Log_Loss = metrics.log_loss(y_test, predictions)\n",
    "print(\"KNN Accuracy Score: \",KNN_Accuracy_Score)\n",
    "print(\"KNN_JaccardIndex: \",KNN_JaccardIndex)\n",
    "print(\"KNN F1 score : \", KNN_F1_Score)\n",
    "print(\"KNN Log Loss : \", KNN_Log_Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q9) Create and train a Decision Tree model called Tree using the training data (`x_train`, `y_train`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tree = DecisionTreeClassifier(criterion=\"entropy\", max_depth = 4)\n",
    "Tree.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q10) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = Tree.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q11) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree accur_acy score:  0.8183206106870229\n",
      "Tree JaccardIndex :  0.48034934497816595\n",
      "Tree_F1_Score :  0.6489675516224188\n",
      "Tree Log Loss :  6.275038737219435\n"
     ]
    }
   ],
   "source": [
    "Tree_Accuracy_Score = metrics.accuracy_score(y_test, predictions)\n",
    "Tree_JaccardIndex = metrics.jaccard_score(y_test, predictions)\n",
    "Tree_F1_Score = metrics.f1_score(y_test, predictions)\n",
    "Tree_Log_Loss = metrics.log_loss(y_test, predictions)\n",
    "print(\"Tree accur_acy score: \", Tree_Accuracy_Score)\n",
    "print(\"Tree JaccardIndex : \", Tree_JaccardIndex)\n",
    "print(\"Tree_F1_Score : \", Tree_F1_Score)\n",
    "print(\"Tree Log Loss : \", Tree_Log_Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q12) Use the `train_test_split` function to split the `features` and `Y` dataframes with a `test_size` of `0.2` and the `random_state` set to `1`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (2616, 66) (2616,)\n",
      "Test set: (655, 66) (655,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test =  train_test_split(features, Y, test_size = 0.2, random_state =1)\n",
    "print ('Train set:', x_train.shape,  y_train.shape)\n",
    "print ('Test set:', x_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q13) Create and train a LogisticRegression model called LR using the training data (`x_train`, `y_train`) with the `solver` parameter set to `liblinear`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = LogisticRegression(C=0.01, solver='liblinear').fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q14) Now, use the `predict` and `predict_proba` methods on the testing data (`x_test`) and save it as 2 arrays `predictions` and `predict_proba`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = LR.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba = LR.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q15) Using the `predictions`, `predict_proba` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR accuracy score:  0.8274809160305343\n",
      "LR JaccardIndex :  0.4840182648401826\n",
      "LR F1 Score :  0.6523076923076923\n",
      "LR Log Loss :  5.958643233175305\n"
     ]
    }
   ],
   "source": [
    "LR_Accuracy_Score = metrics.accuracy_score(y_test,predictions)\n",
    "LR_JaccardIndex = metrics.jaccard_score(y_test,predictions)\n",
    "LR_F1_Score = metrics.f1_score(y_test,predictions)\n",
    "LR_Log_Loss = metrics.log_loss(y_test, predictions)\n",
    "print(\"LR accuracy score: \", LR_Accuracy_Score)\n",
    "print(\"LR JaccardIndex : \", LR_JaccardIndex)\n",
    "print(\"LR F1 Score : \", LR_F1_Score)\n",
    "print(\"LR Log Loss : \", LR_Log_Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q16) Create and train a SVM model called SVM using the training data (`x_train`, `y_train`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM = svm.SVC(kernel='linear')\n",
    "SVM.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q17) Now use the `predict` method on the testing data (`x_test`) and save it to the array `predictions`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = SVM.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q18) Using the `predictions` and the `y_test` dataframe calculate the value for each metric using the appropriate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy score :  0.833587786259542\n",
      "SVM jaccardIndex :  0.49537037037037035\n",
      "SVM F1_score :  0.6625386996904025\n",
      "SVM Log Loss :  5.747715745584566\n"
     ]
    }
   ],
   "source": [
    "SVM_Accuracy_Score =  metrics.accuracy_score(y_test, predictions)\n",
    "SVM_JaccardIndex = metrics.jaccard_score(y_test, predictions) \n",
    "SVM_F1_Score =  metrics.f1_score(y_test, predictions)\n",
    "SVM_Log_Loss = metrics.log_loss(y_test, predictions)\n",
    "print(\"SVM accuracy score : \", SVM_Accuracy_Score)\n",
    "print(\"SVM jaccardIndex : \", SVM_JaccardIndex)\n",
    "print(\"SVM F1_score : \", SVM_F1_Score)\n",
    "print(\"SVM Log Loss : \", SVM_Log_Loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q19) Show the Accuracy,Jaccard Index,F1-Score and LogLoss in a tabular format using data frame for all of the above models.\n",
    "\n",
    "\\*LogLoss is only for Logistic Regression Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+----------+----------+----------+\n",
      "|               |      KNN |     Tree |       LR |      SVM |\n",
      "|---------------+----------+----------+----------+----------|\n",
      "| Accuracy      | 0.818321 | 0.818321 | 0.827481 | 0.833588 |\n",
      "| Jaccard Index | 0.425121 | 0.480349 | 0.484018 | 0.49537  |\n",
      "| F1-Score      | 0.59661  | 0.648968 | 0.652308 | 0.662539 |\n",
      "| LogLoss       | 6.27501  | 6.27504  | 5.95864  | 5.74772  |\n",
      "+---------------+----------+----------+----------+----------+\n"
     ]
    }
   ],
   "source": [
    "d = {'KNN':[KNN_Accuracy_Score,KNN_JaccardIndex,KNN_F1_Score,KNN_Log_Loss],\n",
    "     'Tree':[Tree_Accuracy_Score, Tree_JaccardIndex, Tree_F1_Score, Tree_Log_Loss],\n",
    "     'LR':[LR_Accuracy_Score, LR_JaccardIndex, LR_F1_Score,LR_Log_Loss],\n",
    "     'SVM':[SVM_Accuracy_Score, SVM_JaccardIndex, SVM_F1_Score, SVM_Log_Loss]}\n",
    "Report = pd.DataFrame(data=d, index = ['Accuracy','Jaccard Index','F1-Score', 'LogLoss'])\n",
    "print(tabulate(Report, headers = 'keys', tablefmt = 'psql')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\">  <h3/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
